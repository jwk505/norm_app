# inventory_report_app.py
# ============================================================
# Norm ERP Console (ìš´ì˜ìš© ë‹¨ì¼ íŒŒì¼, ìµœì¢… í†µí•©ë³¸)
#
# ë©”ë‰´
# 1) ì¬ê³  / í’ˆëª© ë§¤í•‘ (inventory_snapshot + item_master)
# 2) ë§¤ì¶œ ì—‘ì…€ â†’ DB ì ì¬ (sales_raw)  *ê¸°ë³¸: íŒŒì¼ ì—…ë¡œë“œ*
# 3) ê±°ë˜ì²˜ ì •ê·œí™” (customer_alias â†’ customer_master)
# 4) ê±°ë˜ì²˜ ì „ëµ ë¦¬í¬íŠ¸ (ì •ê·œí™” ê¸°ì¤€ TOP/ì„±ì¥/ê°ì†Œ + í™•ì¥ë·°ë¡œ raw alias í‘œì‹œ)
#
# ì‹¤í–‰:
#   python -m streamlit run inventory_report_app.py
#
# .env (C:\norm_app\.env) ì˜ˆì‹œ:
#   DB_HOST=127.0.0.1
#   DB_USER=normuser
#   DB_PASS=ë¹„ë°€ë²ˆí˜¸
#   DB_NAME=normdb
#   DB_PORT=3306
# ============================================================

import os
from pathlib import Path
from typing import Optional, Tuple, Set, List

import pandas as pd
import streamlit as st
import mysql.connector
from dotenv import load_dotenv


# =============================
# ENV / PATH
# =============================
BASE_DIR = Path(__file__).resolve().parent
ENV_PATH = BASE_DIR / ".env"
load_dotenv(dotenv_path=ENV_PATH, override=True)

DB_HOST = os.getenv("DB_HOST", "127.0.0.1")
DB_USER = os.getenv("DB_USER")
DB_PASS = os.getenv("DB_PASS") or ""
DB_NAME = os.getenv("DB_NAME", "normdb")
DB_PORT = int(os.getenv("DB_PORT", "3306"))

DEFAULT_SALES_XLSX = BASE_DIR / "20-25ë…„_ì „ì²´ë§¤ì¶œ.xlsx"


# =============================
# DB Helpers
# =============================
def get_conn():
    if not DB_USER:
        raise RuntimeError("DB_USERê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    return mysql.connector.connect(
        host=DB_HOST,
        user=DB_USER,
        password=DB_PASS,
        database=DB_NAME,
        port=DB_PORT,
    )


@st.cache_data(ttl=60)
def query_df(sql: str, params: Tuple = ()) -> pd.DataFrame:
    conn = get_conn()
    try:
        cur = conn.cursor()
        cur.execute(sql, params)
        cols = [c[0] for c in cur.description] if cur.description else []
        rows = cur.fetchall() if cur.description else []
        cur.close()
        return pd.DataFrame(rows, columns=cols)
    finally:
        conn.close()


def exec_sql(sql: str, params: Tuple = ()) -> int:
    conn = get_conn()
    try:
        cur = conn.cursor()
        cur.execute(sql, params)
        conn.commit()
        rc = cur.rowcount
        cur.close()
        return int(rc)
    finally:
        conn.close()


def exec_many(sql: str, rows: List[Tuple]) -> int:
    if not rows:
        return 0
    conn = get_conn()
    try:
        cur = conn.cursor()
        cur.executemany(sql, rows)
        conn.commit()
        cur.close()
        return int(len(rows))
    finally:
        conn.close()


@st.cache_data(ttl=300)
def get_columns(table_name: str) -> Set[str]:
    df = query_df(
        """
        SELECT COLUMN_NAME
        FROM INFORMATION_SCHEMA.COLUMNS
        WHERE TABLE_SCHEMA = %s AND TABLE_NAME = %s
        """,
        (DB_NAME, table_name),
    )
    if df.empty:
        return set()
    return set(df["COLUMN_NAME"].astype(str).tolist())


@st.cache_data(ttl=300)
def table_exists(table_name: str) -> bool:
    df = query_df(
        """
        SELECT COUNT(*) AS c
        FROM INFORMATION_SCHEMA.TABLES
        WHERE TABLE_SCHEMA=%s AND TABLE_NAME=%s
        """,
        (DB_NAME, table_name),
    )
    return (not df.empty) and int(df.iloc[0]["c"]) > 0


# =============================
# Formatting / common helpers
# =============================
def style_numbers(df: pd.DataFrame, num_cols: Optional[List] = None):
    """Pandas Styler: None/NaN ì•ˆì „ + ìˆ«ì ì½¤ë§ˆ + ì˜¤ë¥¸ìª½ ì •ë ¬"""
    if df is None or df.empty:
        return df

    if num_cols is None:
        candidates = [
            "qty", "stock_value", "line_cnt",
            "amount", "TOTAL", "GROWTH_23_25", "GROWTH_24_25",
            2020, 2021, 2022, 2023, 2024, 2025,
        ]
        num_cols = [c for c in candidates if c in df.columns]

    def fmt(x):
        try:
            if x is None or (isinstance(x, float) and pd.isna(x)) or pd.isna(x):
                return ""
            return f"{float(x):,.0f}"
        except Exception:
            return x

    fmt_map = {c: fmt for c in num_cols if c in df.columns}
    sty = df.style.format(fmt_map)

    right_cols = [c for c in num_cols if c in df.columns]
    if right_cols:
        sty = sty.set_properties(subset=right_cols, **{"text-align": "right"})
    return sty


def parse_year(val) -> Optional[int]:
    if val is None or (isinstance(val, float) and pd.isna(val)):
        return None
    s = str(val).strip().replace("ë…„", "").strip()
    try:
        y = int(float(s))
        if 2000 <= y <= 2100:
            return y
    except Exception:
        return None
    return None


def normalize_str_series(s: pd.Series) -> pd.Series:
    s = s.astype("string").str.strip()
    s = s.replace({"": pd.NA, "nan": pd.NA, "None": pd.NA})
    return s


# =============================
# Inventory helpers
# =============================
def pick_maker_expr(item_cols: Set[str], snap_cols: Set[str]) -> Tuple[str, str]:
    candidates = ["maker", "brand", "make", "mfg", "manufacturer"]
    s_col = next((c for c in candidates if c in snap_cols), None)
    m_col = next((c for c in candidates if c in item_cols), None)

    if s_col and m_col:
        return (
            f"s.{s_col}/m.{m_col}",
            f"IFNULL(NULLIF(TRIM(s.{s_col}),''), IFNULL(NULLIF(TRIM(m.{m_col}),''), '(UNKNOWN)'))",
        )
    if s_col:
        return (f"s.{s_col}", f"IFNULL(NULLIF(TRIM(s.{s_col}),''), '(UNKNOWN)')")
    if m_col:
        return (f"m.{m_col}", f"IFNULL(NULLIF(TRIM(m.{m_col}),''), '(UNKNOWN)')")
    return ("(none)", "'(UNKNOWN)'")


# =============================
# Sales Excel multi-sheet loader (header auto-detect)
# =============================
def _find_header_row(df_no_header: pd.DataFrame, needle: str = "ë…„ë„", max_scan: int = 40) -> Optional[int]:
    n = min(max_scan, len(df_no_header))
    for i in range(n):
        row_vals = df_no_header.iloc[i].astype(str).tolist()
        if any(needle in v for v in row_vals):
            return i
    return None


def _read_one_sheet_any_header(excel_source, sheet_name) -> pd.DataFrame:
    raw = pd.read_excel(excel_source, sheet_name=sheet_name, header=None, engine="openpyxl")
    header_row = _find_header_row(raw, needle="ë…„ë„", max_scan=40)

    if header_row is None:
        df = raw.copy()
        df.columns = [f"Unnamed_{i}" for i in range(df.shape[1])]
    else:
        df = pd.read_excel(excel_source, sheet_name=sheet_name, header=header_row, engine="openpyxl")

    df["_sheet"] = str(sheet_name)
    df["_header_row"] = header_row
    return df


@st.cache_data(ttl=300)
def load_sales_all_sheets(upload_or_path) -> pd.DataFrame:
    xls = pd.ExcelFile(upload_or_path, engine="openpyxl")
    frames = [_read_one_sheet_any_header(upload_or_path, sh) for sh in xls.sheet_names]
    return pd.concat(frames, ignore_index=True, sort=False)


def is_sheet_2425(sheet_name: str) -> bool:
    s = str(sheet_name)
    if "24-25" in s:
        return True
    if "24" in s and "25" in s:
        return True
    return False


def detect_year_col(df: pd.DataFrame) -> Optional[str]:
    if "ë…„ë„" in df.columns:
        return "ë…„ë„"
    if "ì—°ë„" in df.columns:
        return "ì—°ë„"
    return None


def detect_amount_col(df: pd.DataFrame) -> Optional[str]:
    for c in ["ê³µê¸‰ê°€ì•¡", "ë§¤ì¶œì•¡", "ë§¤ì¶œ", "ê¸ˆì•¡", "ê³µê¸‰ê°€", "ë§¤ì¶œê¸ˆì•¡"]:
        if c in df.columns:
            return c
    return None


def pick_customer_col_for_sheet(df: pd.DataFrame, sheet: str) -> Optional[str]:
    # 24-25 ì‹œíŠ¸: ì‚¬ìš©ìƒí˜¸ ìš°ì„ 
    if is_sheet_2425(sheet):
        if "ì‚¬ìš©ìƒí˜¸" in df.columns:
            return "ì‚¬ìš©ìƒí˜¸"
        if "ê±°ë˜ì²˜ëª…" in df.columns:
            return "ê±°ë˜ì²˜ëª…"
        if "ê±°ë˜ì²˜" in df.columns:
            return "ê±°ë˜ì²˜"
        return None

    # ê·¸ ì™¸: ê±°ë˜ì²˜ëª… ìš°ì„ 
    if "ê±°ë˜ì²˜ëª…" in df.columns:
        return "ê±°ë˜ì²˜ëª…"
    if "ê±°ë˜ì²˜" in df.columns:
        return "ê±°ë˜ì²˜"
    if "ì‚¬ìš©ìƒí˜¸" in df.columns:
        return "ì‚¬ìš©ìƒí˜¸"
    return None


# =============================
# Page 1: Inventory / Item Mapping
# =============================
def show_inventory_page():
    st.subheader("ì¬ê³  / í’ˆëª© ë§¤í•‘ (inventory_snapshot)")
    if not table_exists("inventory_snapshot"):
        st.error("DBì— inventory_snapshot í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    if not table_exists("item_master"):
        st.error("DBì— item_master í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    item_cols = get_columns("item_master")
    snap_cols = get_columns("inventory_snapshot")
    maker_label, maker_col_expr = pick_maker_expr(item_cols, snap_cols)

    # source_system ëª©ë¡
    src_df = query_df("SELECT DISTINCT source_system FROM inventory_snapshot ORDER BY source_system")
    src_options = src_df["source_system"].dropna().astype(str).tolist() if not src_df.empty else ["INV_SUM"]
    default_src = "INV_SUM" if "INV_SUM" in src_options else (src_options[0] if src_options else "INV_SUM")

    with st.expander("ì—°ê²°ì •ë³´/ìŠ¤í‚¤ë§ˆ(ë””ë²„ê·¸)", expanded=False):
        st.write("DB_HOST =", DB_HOST)
        st.write("DB_USER =", DB_USER)
        st.write("DB_PASS SET =", bool(DB_PASS.strip()))
        st.write("DB_NAME =", DB_NAME)
        st.write("DB_PORT =", DB_PORT)
        st.write("ENV_PATH =", str(ENV_PATH))
        st.write("Maker expr =", maker_label, "=>", maker_col_expr)

    st.sidebar.header("ì¬ê³  í•„í„°")
    source_system = st.sidebar.selectbox(
        "Source System",
        src_options,
        index=src_options.index(default_src) if default_src in src_options else 0,
        key="inv_source_system",
    )
    view_mode = st.sidebar.radio("ë³´ê¸° ëª¨ë“œ", ["ë§¤í•‘ëœ í’ˆëª©", "ë¯¸ë§¤í•‘ í’ˆëª©"], index=0, key="inv_view_mode")
    enable_mapping_ui = st.sidebar.checkbox("ë¯¸ë§¤í•‘ ë§¤í•‘ UI í‘œì‹œ", value=True, key="inv_enable_mapping_ui")
    show_all = st.sidebar.checkbox("ì „ì²´ ë³´ê¸° (LIMIT í•´ì œ)", value=False, key="inv_show_all")
    top_n = st.sidebar.slider("TOP N", 10, 500, 100, 10, disabled=show_all, key="inv_topn")
    min_stock_value = st.sidebar.number_input("ìµœì†Œ ì¬ê³ ê¸ˆì•¡(ì›)", min_value=0.0, value=0.0, step=10000.0, key="inv_min_stock_value")
    search_item = st.sidebar.text_input("í’ˆëª© ê²€ìƒ‰(ë¶€ë¶„ì¼ì¹˜)", value="", key="inv_search_item")
    only_outliers = st.sidebar.checkbox("ì´ìƒì¹˜(0ìˆ˜ëŸ‰/ìŒìˆ˜ìˆ˜ëŸ‰)ë§Œ", value=False, key="inv_only_outliers")
    show_line_items = st.sidebar.checkbox("ì„ íƒ ê·¸ë£¹ ìƒì„¸ ë¼ì¸ ë³´ê¸°", value=True, key="inv_show_line_items")

    limit_sql = "" if show_all else f"LIMIT {int(top_n)}"

    # maker ëª©ë¡
    maker_list_df = query_df(
        f"""
        SELECT DISTINCT {maker_col_expr} AS maker
        FROM inventory_snapshot s
        LEFT JOIN item_master m ON m.id = s.mapped_item_id
        WHERE s.source_system=%s
        ORDER BY maker
        """,
        (source_system,),
    )
    maker_options = ["(ALL)"] + (maker_list_df["maker"].dropna().astype(str).tolist() if not maker_list_df.empty else [])
    maker = st.sidebar.selectbox("Maker", maker_options, index=0, key="inv_maker")

    # WHERE + params
    where: List[str] = ["s.source_system=%s"]
    params: List = [source_system]

    if maker != "(ALL)":
        where.append(f"{maker_col_expr} = %s")
        params.append(maker)

    if float(min_stock_value) > 0:
        where.append("s.stock_value >= %s")
        params.append(float(min_stock_value))

    if only_outliers:
        where.append("(s.qty <= 0)")

    if search_item.strip():
        like = f"%{search_item.strip()}%"
        where.append("(s.raw_item LIKE %s OR s.norm_item LIKE %s)")
        params.extend([like, like])
        if view_mode == "ë§¤í•‘ëœ í’ˆëª©" and "display_name" in item_cols:
            where[-1] = "(s.raw_item LIKE %s OR s.norm_item LIKE %s OR m.display_name LIKE %s)"
            params.append(like)

    if view_mode == "ë§¤í•‘ëœ í’ˆëª©":
        where.append("(s.mapped_item_id IS NOT NULL AND s.mapped_item_id <> 0)")
    else:
        where.append("(s.mapped_item_id IS NULL OR s.mapped_item_id = 0)")

    where_sql = " AND ".join(where)

    # Summary SQL
    if view_mode == "ë§¤í•‘ëœ í’ˆëª©":
        item_name_expr = "m.display_name" if "display_name" in item_cols else "CAST(s.norm_item AS CHAR)"
        item_id_expr = "s.mapped_item_id"
        group_expr = "s.mapped_item_id, item, maker"
    else:
        item_name_expr = "CAST(s.norm_item AS CHAR)"
        item_id_expr = "0"
        group_expr = "item, maker"

    summary_sql = f"""
    SELECT
      {item_id_expr} AS item_id,
      {item_name_expr} AS item,
      {maker_col_expr} AS maker,
      COALESCE(SUM(s.qty),0) AS qty,
      COALESCE(SUM(s.stock_value),0) AS stock_value,
      COUNT(*) AS line_cnt
    FROM inventory_snapshot s
    LEFT JOIN item_master m ON m.id = s.mapped_item_id
    WHERE {where_sql}
    GROUP BY {group_expr}
    ORDER BY stock_value DESC
    {limit_sql}
    """
    summary_df = query_df(summary_sql, tuple(params))

    total_qty = float(summary_df["qty"].sum()) if (summary_df is not None and not summary_df.empty and "qty" in summary_df.columns) else 0.0
    total_value = float(summary_df["stock_value"].sum()) if (summary_df is not None and not summary_df.empty and "stock_value" in summary_df.columns) else 0.0

    k1, k2, k3 = st.columns(3)
    k1.metric("í‘œì‹œ ê·¸ë£¹ ìˆ˜", f"{len(summary_df):,}")
    k2.metric("í‘œì‹œ ì¬ê³ ìˆ˜ëŸ‰ í•©ê³„", f"{int(total_qty):,}")
    k3.metric("í‘œì‹œ ì¬ê³ ê¸ˆì•¡ í•©ê³„(ì›)", f"{int(total_value):,}")

    st.subheader("ìš”ì•½")
    st.dataframe(style_numbers(summary_df, num_cols=["qty", "stock_value", "line_cnt"]), use_container_width=True, hide_index=True)

    # Unmapped mapping UI
    if enable_mapping_ui and view_mode == "ë¯¸ë§¤í•‘ í’ˆëª©":
        st.divider()
        st.header("ë¯¸ë§¤í•‘ í’ˆëª© ë§¤í•‘ (MVP)")

        unmapped_sql = f"""
        SELECT
          CAST(s.norm_item AS CHAR) AS norm_item,
          {maker_col_expr} AS maker,
          COALESCE(SUM(s.qty),0) AS qty,
          COALESCE(SUM(s.stock_value),0) AS stock_value,
          COUNT(*) AS line_cnt
        FROM inventory_snapshot s
        LEFT JOIN item_master m ON m.id = s.mapped_item_id
        WHERE s.source_system=%s
          AND (s.mapped_item_id IS NULL OR s.mapped_item_id=0)
          AND (s.norm_item IS NOT NULL AND TRIM(s.norm_item) <> '')
        GROUP BY norm_item, maker
        ORDER BY stock_value DESC
        LIMIT 300
        """
        unmapped_df = query_df(unmapped_sql, (source_system,))

        if unmapped_df is None or unmapped_df.empty:
            st.info("ë¯¸ë§¤í•‘ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            left, right = st.columns([1, 2])

            with left:
                st.subheader("ë¯¸ë§¤í•‘ TOP (norm_item)")
                st.dataframe(style_numbers(unmapped_df, num_cols=["qty", "stock_value", "line_cnt"]), use_container_width=True, hide_index=True)

                options = [
                    f"{r.norm_item} | {r.maker} | {int((r.stock_value or 0)):,}ì› ({int((r.line_cnt or 0)):,} lines)"
                    for r in unmapped_df.itertuples(index=False)
                ]
                picked = st.selectbox("ë§¤í•‘í•  norm_item ì„ íƒ", options, index=0, key="inv_pick_norm_item")
                selected_norm_item = picked.split(" | ")[0].strip()

            with right:
                st.subheader("ì„ íƒ norm_item ë¼ì¸ ìƒ˜í”Œ")
                sample_sql = """
                SELECT
                  s.id, s.raw_item, s.norm_item, s.qty, s.stock_value, s.created_at
                FROM inventory_snapshot s
                WHERE s.source_system=%s
                  AND s.norm_item=%s
                  AND (s.mapped_item_id IS NULL OR s.mapped_item_id=0)
                ORDER BY s.stock_value DESC, s.qty DESC
                LIMIT 50
                """
                sample_df = query_df(sample_sql, (source_system, selected_norm_item))
                st.dataframe(style_numbers(sample_df, num_cols=["qty", "stock_value"]), use_container_width=True, hide_index=True)

                st.markdown("### ê¸°ì¤€ í’ˆëª©(item_master) ê²€ìƒ‰")
                q = st.text_input("ê²€ìƒ‰ì–´(ê¸°ì¤€í’ˆëª©ëª… ì¼ë¶€)", value="", key="inv_item_search_q")

                name_col = "display_name" if "display_name" in item_cols else ("name" if "name" in item_cols else None)
                if not name_col:
                    st.warning("item_masterì— display_name/name ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤. ê²€ìƒ‰ ì»¬ëŸ¼ì„ ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ìˆ˜ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
                else:
                    like = f"%{q.strip()}%" if q.strip() else "%"

                    maker_col_in_master = next((c for c in ["maker", "brand", "make", "mfg", "manufacturer"] if c in item_cols), None)

                    if maker_col_in_master:
                        item_search_sql = f"""
                        SELECT id, {name_col} AS item_name, {maker_col_in_master} AS maker
                        FROM item_master
                        WHERE {name_col} LIKE %s
                        ORDER BY {name_col}
                        LIMIT 50
                        """
                    else:
                        item_search_sql = f"""
                        SELECT id, {name_col} AS item_name
                        FROM item_master
                        WHERE {name_col} LIKE %s
                        ORDER BY {name_col}
                        LIMIT 50
                        """

                    cand_df = query_df(item_search_sql, (like,))
                    st.dataframe(cand_df, use_container_width=True, hide_index=True)

                    if cand_df is None or cand_df.empty:
                        st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    else:
                        if "maker" in cand_df.columns:
                            cand_opts = [f"{int(r.id)} | {r.item_name} | {r.maker}" for r in cand_df.itertuples(index=False)]
                        else:
                            cand_opts = [f"{int(r.id)} | {r.item_name}" for r in cand_df.itertuples(index=False)]

                        picked_item = st.selectbox("ë§¤í•‘í•  ê¸°ì¤€ í’ˆëª© ì„ íƒ", cand_opts, index=0, key="inv_pick_item_master")
                        selected_item_id = int(picked_item.split("|")[0].strip())

                        st.markdown("### ë§¤í•‘ ì ìš©")
                        st.caption("ë™ì¼ norm_itemì˜ ë¯¸ë§¤í•‘ ë¼ì¸ ì „ì²´ì— mapped_item_idë¥¼ ì¼ê´„ UPDATE í•©ë‹ˆë‹¤.")

                        if st.button("âœ… ë§¤í•‘(UPDATE)", key="inv_do_mapping"):
                            upd_sql = """
                            UPDATE inventory_snapshot
                            SET mapped_item_id=%s
                            WHERE source_system=%s
                              AND norm_item=%s
                              AND (mapped_item_id IS NULL OR mapped_item_id=0)
                            """
                            affected = exec_sql(upd_sql, (selected_item_id, source_system, selected_norm_item))
                            st.success(f"ë§¤í•‘ ì™„ë£Œ: '{selected_norm_item}' â†’ item_id={selected_item_id} (rows={affected:,})")
                            st.cache_data.clear()
                            st.rerun()

    # Detail lines
    if show_line_items and summary_df is not None and not summary_df.empty:
        st.divider()
        st.subheader("ìƒì„¸(ë¼ì¸)")

        if view_mode == "ë§¤í•‘ëœ í’ˆëª©":
            options = [f"{row.item} (id={int(row.item_id)})" for row in summary_df.itertuples(index=False)]
            picked = st.selectbox("ìƒì„¸ë¡œ ë³¼ í’ˆëª© ì„ íƒ", options, index=0, key="inv_detail_pick_mapped")
            selected_item_id = int(picked.split("id=")[-1].rstrip(")"))

            detail_sql = """
            SELECT
              s.id, s.source_system, s.raw_item, s.norm_item, s.qty, s.stock_value, s.created_at
            FROM inventory_snapshot s
            WHERE s.source_system=%s
              AND s.mapped_item_id = %s
            ORDER BY s.stock_value DESC, s.qty DESC
            LIMIT 1000
            """
            detail_df = query_df(detail_sql, (source_system, selected_item_id))
            st.dataframe(style_numbers(detail_df, num_cols=["qty", "stock_value"]), use_container_width=True, hide_index=True)

            csv = detail_df.to_csv(index=False).encode("utf-8-sig")
            st.download_button(
                "ì„ íƒ í’ˆëª© ìƒì„¸ CSV ë‹¤ìš´ë¡œë“œ",
                data=csv,
                file_name=f"inv_{source_system}_item_{selected_item_id}_detail.csv",
                mime="text/csv",
                key="inv_dl_detail_mapped",
            )

    st.divider()
    st.subheader("ë‹¤ìš´ë¡œë“œ")
    sum_csv = summary_df.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "í˜„ì¬ í•„í„° ê¸°ì¤€ ìš”ì•½ CSV ë‹¤ìš´ë¡œë“œ",
        data=sum_csv,
        file_name=f"inv_{source_system}_{'mapped' if view_mode=='ë§¤í•‘ëœ í’ˆëª©' else 'unmapped'}_summary.csv",
        mime="text/csv",
        key="inv_dl_summary",
    )


# =============================
# Page 2: Sales Excel -> DB Import (default: upload)
# =============================
def show_sales_import_page():
    st.subheader("ë§¤ì¶œ ì—‘ì…€ â†’ DB ì ì¬ (sales_raw)")
    st.caption("ê¸°ë³¸ì€ íŒŒì¼ ì—…ë¡œë“œ. 24-25 ì‹œíŠ¸ëŠ” 'ì‚¬ìš©ìƒí˜¸', ê·¸ ì™¸ëŠ” 'ê±°ë˜ì²˜ëª…'ì„ ìš°ì„  ì‚¬ìš©í•©ë‹ˆë‹¤.")

    needed = ["sales_raw", "customer_master", "customer_alias"]
    missing = [t for t in needed if not table_exists(t)]
    if missing:
        st.error(f"DBì— í•„ìˆ˜ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        st.stop()

    src_mode = st.radio(
        "ë°ì´í„° ì†ŒìŠ¤",
        ["íŒŒì¼ ì—…ë¡œë“œ", "ê¸°ë³¸ íŒŒì¼ ê²½ë¡œ"],
        index=0,
        horizontal=True,
    )

    if src_mode == "íŒŒì¼ ì—…ë¡œë“œ":
        up = st.file_uploader("ë§¤ì¶œ ì—‘ì…€ ì—…ë¡œë“œ (.xlsx)", type=["xlsx"])
        if up is None:
            st.info("ì—‘ì…€ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
            return
        raw = load_sales_all_sheets(up)
        src_file_label = getattr(up, "name", "uploaded.xlsx")
    else:
        if not DEFAULT_SALES_XLSX.exists():
            st.error(f"ê¸°ë³¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DEFAULT_SALES_XLSX}")
            return
        raw = load_sales_all_sheets(str(DEFAULT_SALES_XLSX))
        src_file_label = DEFAULT_SALES_XLSX.name

    year_col = detect_year_col(raw)
    amount_col = detect_amount_col(raw)
    if not year_col:
        st.error("ì—‘ì…€ì—ì„œ 'ë…„ë„'/'ì—°ë„' ì»¬ëŸ¼ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return
    if not amount_col:
        st.error("ì—‘ì…€ì—ì„œ ê¸ˆì•¡ ì»¬ëŸ¼(ê³µê¸‰ê°€ì•¡/ë§¤ì¶œì•¡/ê¸ˆì•¡ ë“±)ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
        return

    delete_before = st.checkbox("ì ì¬ ì „ sales_raw ë¹„ìš°ê¸°(DELETE)", value=False)
    only_2020_2025 = st.checkbox("2020~2025ë§Œ ì ì¬", value=True)

    df = raw.copy()
    df["year"] = df[year_col].apply(parse_year)
    df["amount"] = pd.to_numeric(df[amount_col], errors="coerce")
    df["customer_col"] = None
    df["customer_raw"] = pd.NA

    for idx, r in df.iterrows():
        sheet = str(r["_sheet"])
        cust_col = pick_customer_col_for_sheet(df, sheet)
        df.at[idx, "customer_col"] = cust_col or ""
        if cust_col and cust_col in df.columns:
            df.at[idx, "customer_raw"] = r.get(cust_col)

    df["customer_raw"] = normalize_str_series(df["customer_raw"])
    df = df[df["year"].notna() & df["amount"].notna() & df["customer_raw"].notna()]
    df["year"] = df["year"].astype(int)

    if only_2020_2025:
        df = df[df["year"].between(2020, 2025, inclusive="both")]

    st.subheader("ì ì¬ ëŒ€ìƒ ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 200í–‰)")
    st.dataframe(df[["_sheet", "year", "customer_raw", "amount", "customer_col"]].head(200), use_container_width=True, hide_index=True)

    k1, k2, k3 = st.columns(3)
    k1.metric("ì ì¬ ëŒ€ìƒ í–‰ ìˆ˜", f"{len(df):,}")
    k2.metric("ê±°ë˜ì²˜(ì›ë¬¸) ìˆ˜", f"{df['customer_raw'].nunique():,}")
    k3.metric("ê¸ˆì•¡ í•©ê³„", f"{int(df['amount'].sum()):,}")

    if st.button("ğŸ“¥ DB ì ì¬ ì‹¤í–‰"):
        if delete_before:
            deleted = exec_sql("DELETE FROM sales_raw")
            st.info(f"sales_raw ì‚­ì œ: {deleted:,} rows")

        insert_sql = """
        INSERT INTO sales_raw (src_file, sheet_name, year, customer_raw, amount, customer_col)
        VALUES (%s, %s, %s, %s, %s, %s)
        """

        rows: List[Tuple] = []
        for _, r in df.iterrows():
            rows.append(
                (
                    src_file_label,
                    str(r["_sheet"]),
                    int(r["year"]),
                    str(r["customer_raw"]),
                    float(r["amount"]),
                    str(r["customer_col"]),
                )
            )

        inserted = exec_many(insert_sql, rows)
        st.success(f"sales_raw ì ì¬ ì™„ë£Œ: {inserted:,} rows")

        exec_sql(
            """
            INSERT INTO customer_alias (alias_name, src_hint)
            SELECT DISTINCT customer_raw, customer_col
            FROM sales_raw
            WHERE customer_raw IS NOT NULL AND TRIM(customer_raw) <> ''
            ON DUPLICATE KEY UPDATE src_hint = VALUES(src_hint)
            """
        )
        st.info("customer_alias ìë™ ìˆ˜ì§‘ ì™„ë£Œ.")

        st.cache_data.clear()
        st.rerun()


# =============================
# Page 3: Customer Normalization
# =============================
def show_customer_normalize_page():
    st.subheader("ê±°ë˜ì²˜ ì •ê·œí™” (alias â†’ master)")
    needed = ["sales_raw", "customer_master", "customer_alias"]
    missing = [t for t in needed if not table_exists(t)]
    if missing:
        st.error(f"DBì— í•„ìˆ˜ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        return

    unmapped_df = query_df(
        """
        SELECT
          ca.alias_name,
          ca.src_hint,
          COALESCE(SUM(sr.amount),0) AS total_sales,
          COUNT(sr.id) AS line_cnt
        FROM customer_alias ca
        LEFT JOIN sales_raw sr ON sr.customer_raw = ca.alias_name
        WHERE ca.customer_id IS NULL
        GROUP BY ca.alias_name, ca.src_hint
        ORDER BY total_sales DESC
        LIMIT 300
        """
    )

    mapped_cnt = query_df("SELECT COUNT(*) AS c FROM customer_alias WHERE customer_id IS NOT NULL").iloc[0]["c"]
    all_cnt = query_df("SELECT COUNT(*) AS c FROM customer_alias").iloc[0]["c"]
    progress = 0.0 if int(all_cnt) == 0 else float(mapped_cnt) / float(all_cnt)

    k1, k2, k3 = st.columns(3)
    k1.metric("ë¯¸ë§¤í•‘ alias ìˆ˜", f"{len(unmapped_df):,}")
    k2.metric("ë§¤í•‘ ì™„ë£Œ alias ìˆ˜", f"{int(mapped_cnt):,}")
    k3.metric("ì§„í–‰ë¥ ", f"{progress*100:,.1f}%")

    st.subheader("ë¯¸ë§¤í•‘ alias TOP")
    st.dataframe(style_numbers(unmapped_df, num_cols=["total_sales", "line_cnt"]), use_container_width=True, hide_index=True)

    if unmapped_df is None or unmapped_df.empty:
        st.info("ë¯¸ë§¤í•‘ aliasê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    options = [
        f"{r.alias_name} | {r.src_hint} | {int((r.total_sales or 0)):,}ì›"
        for r in unmapped_df.itertuples(index=False)
    ]
    picked = st.selectbox("ì •ê·œí™”í•  alias ì„ íƒ", options, index=0)
    alias_name = picked.split(" | ")[0].strip()

    left, right = st.columns([1, 1])

    with left:
        st.subheader("ê¸°ì¡´ ê¸°ì¤€ ê±°ë˜ì²˜ ì„ íƒ")
        q = st.text_input("ê²€ìƒ‰ì–´(ëŒ€í‘œ ê±°ë˜ì²˜ëª… ì¼ë¶€)", value="", key="cust_search_q")
        like = f"%{q.strip()}%" if q.strip() else "%"

        master_df = query_df(
            """
            SELECT id, display_name, erp_customer_code, is_active
            FROM customer_master
            WHERE display_name LIKE %s
            ORDER BY display_name
            LIMIT 100
            """,
            (like,),
        )
        st.dataframe(master_df, use_container_width=True, hide_index=True)

        if master_df is not None and not master_df.empty:
            opts = [f"{int(r.id)} | {r.display_name}" for r in master_df.itertuples(index=False)]
            pick_master = st.selectbox("ì„ íƒ", opts, index=0, key="cust_pick_master")
            master_id = int(pick_master.split("|")[0].strip())

            if st.button("ğŸ”— ì„ íƒ ê±°ë˜ì²˜ë¡œ ë§¤í•‘(UPDATE)", key="cust_do_map"):
                rc = exec_sql(
                    "UPDATE customer_alias SET customer_id=%s WHERE alias_name=%s",
                    (master_id, alias_name),
                )
                st.success(f"ë§¤í•‘ ì™„ë£Œ: {alias_name} â†’ customer_id={master_id} (rows={rc:,})")
                st.cache_data.clear()
                st.rerun()

    with right:
        st.subheader("ì‹ ê·œ ê±°ë˜ì²˜ ìƒì„± + ë§¤í•‘")
        new_name = st.text_input("ëŒ€í‘œ ê±°ë˜ì²˜ëª…(display_name)", value=alias_name, key="cust_new_name")
        erp_code = st.text_input("ERP ê±°ë˜ì²˜ ì½”ë“œ(ì„ íƒ)", value="", key="cust_new_erp")
        is_active = st.checkbox("í™œì„±", value=True, key="cust_new_active")

        if st.button("â• ìƒì„± + ë§¤í•‘", key="cust_create_map"):
            exec_sql(
                """
                INSERT INTO customer_master (display_name, erp_customer_code, is_active)
                VALUES (%s, %s, %s)
                ON DUPLICATE KEY UPDATE
                  erp_customer_code = COALESCE(NULLIF(VALUES(erp_customer_code),''), erp_customer_code),
                  is_active = VALUES(is_active)
                """,
                (new_name, erp_code.strip(), 1 if is_active else 0),
            )
            mid_df = query_df("SELECT id FROM customer_master WHERE display_name=%s", (new_name,))
            master_id = int(mid_df.iloc[0]["id"])
            exec_sql("UPDATE customer_alias SET customer_id=%s WHERE alias_name=%s", (master_id, alias_name))
            st.success(f"ìƒì„±/ê°±ì‹  + ë§¤í•‘ ì™„ë£Œ: {alias_name} â†’ {new_name} (id={master_id})")
            st.cache_data.clear()
            st.rerun()


# =============================
# Strategy helpers (expander alias view)
# =============================
@st.cache_data(ttl=120)
def get_alias_list_by_customer_id(customer_id: int) -> List[str]:
    df = query_df(
        """
        SELECT alias_name
        FROM customer_alias
        WHERE customer_id=%s
        ORDER BY alias_name
        """,
        (customer_id,),
    )
    if df is None or df.empty:
        return []
    return df["alias_name"].astype(str).tolist()


# =============================
# Page 4: Strategy report + expanders showing raw aliases
# =============================
def show_strategy_page():
    st.subheader("ê±°ë˜ì²˜ ì „ëµ ë¦¬í¬íŠ¸ (ì •ê·œí™” ê¸°ì¤€)")
    st.caption("ëŒ€í‘œ ê±°ë˜ì²˜ ê¸°ì¤€ ì§‘ê³„ + ì•„ë˜ì—ì„œ í¼ì¹˜ë©´ raw ê±°ë˜ì²˜ëª…(alias) ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    needed = ["sales_raw", "customer_master", "customer_alias"]
    missing = [t for t in needed if not table_exists(t)]
    if missing:
        st.error(f"DBì— í•„ìˆ˜ í…Œì´ë¸”ì´ ì—†ìŠµë‹ˆë‹¤: {missing}")
        return

    df = query_df(
        """
        SELECT
          cm.id AS customer_id,
          cm.display_name AS customer,
          sr.year,
          SUM(sr.amount) AS amount
        FROM sales_raw sr
        JOIN customer_alias ca ON ca.alias_name = sr.customer_raw
        JOIN customer_master cm ON cm.id = ca.customer_id
        WHERE sr.year BETWEEN 2020 AND 2025
        GROUP BY cm.id, cm.display_name, sr.year
        """
    )

    if df is None or df.empty:
        st.info("ì •ê·œí™”ëœ ë§¤ì¶œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤. (ê±°ë˜ì²˜ ì •ê·œí™”ì—ì„œ ë§¤í•‘ì„ ë¨¼ì € ì§„í–‰í•˜ì„¸ìš”)")
        return

    pivot = (
        df.pivot_table(index=["customer_id", "customer"], columns="year", values="amount", aggfunc="sum", fill_value=0)
        .reset_index()
    )

    for y in [2020, 2021, 2022, 2023, 2024, 2025]:
        if y not in pivot.columns:
            pivot[y] = 0

    pivot["TOTAL"] = pivot[[2020, 2021, 2022, 2023, 2024, 2025]].sum(axis=1)
    pivot["GROWTH_23_25"] = pivot[2025] - pivot[2023]
    pivot["GROWTH_24_25"] = pivot[2025] - pivot[2024]

    top_n = st.sidebar.slider("TOP N", 10, 300, 50, 10, key="str_topn")

    k1, k2, k3 = st.columns(3)
    k1.metric("ì •ê·œí™” ê±°ë˜ì²˜ ìˆ˜", f"{pivot['customer_id'].nunique():,}")
    k2.metric("ì´ ë§¤ì¶œ(20~25)", f"{int(pivot['TOTAL'].sum()):,}")
    k3.metric("25ë…„ ë§¤ì¶œ", f"{int(pivot[2025].sum()):,}")

    # ---- TOP table
    st.subheader("TOP ê±°ë˜ì²˜ (2020~2025 ëˆ„ì )")
    top = pivot.sort_values("TOTAL", ascending=False).head(int(top_n))
    st.dataframe(style_numbers(top, num_cols=[2020, 2021, 2022, 2023, 2024, 2025, "TOTAL"]), use_container_width=True, hide_index=True)

    st.markdown("### TOP ê±°ë˜ì²˜ë³„ raw ê±°ë˜ì²˜ëª…(alias) ë³´ê¸° (í™•ì¥)")
    for r in top.itertuples(index=False):
        cid = int(r.customer_id)
        cname = str(r.customer)
        total = float(r.TOTAL)
        with st.expander(f"{cname}  |  TOTAL {int(total):,}ì›  |  customer_id={cid}"):
            aliases = get_alias_list_by_customer_id(cid)
            if not aliases:
                st.info("ì—°ê²°ëœ aliasê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                st.write("**raw ê±°ë˜ì²˜ëª…(alias) ëª©ë¡**")
                st.dataframe(pd.DataFrame({"alias_name": aliases}), use_container_width=True, hide_index=True)

    # ---- Growth / Decrease tables (ì„ íƒ)
    st.subheader("ì„±ì¥ ê±°ë˜ì²˜ (2023â†’2025)")
    grow = pivot.sort_values("GROWTH_23_25", ascending=False).head(int(top_n))
    st.dataframe(style_numbers(grow, num_cols=[2023, 2024, 2025, "GROWTH_23_25"]), use_container_width=True, hide_index=True)

    st.subheader("ê°ì†Œ ê±°ë˜ì²˜ (2023â†’2025)")
    dec = pivot.sort_values("GROWTH_23_25", ascending=True).head(int(top_n))
    st.dataframe(style_numbers(dec, num_cols=[2023, 2024, 2025, "GROWTH_23_25"]), use_container_width=True, hide_index=True)

    st.divider()
    st.subheader("ë‹¤ìš´ë¡œë“œ")
    csv = pivot.to_csv(index=False).encode("utf-8-sig")
    st.download_button(
        "ì •ê·œí™” ê±°ë˜ì²˜Ã—ì—°ë„ Pivot CSV ë‹¤ìš´ë¡œë“œ",
        data=csv,
        file_name="normalized_customer_year_sales_pivot_2020_2025.csv",
        mime="text/csv",
    )


# =============================
# Main
# =============================
st.set_page_config(page_title="Norm ERP Console", layout="wide")
st.title("Norm ERP Console")

st.sidebar.header("ë©”ë‰´")
menu = st.sidebar.radio(
    "ì„ íƒ",
    [
        "ì¬ê³  / í’ˆëª© ë§¤í•‘",
        "ë§¤ì¶œ ì—‘ì…€ â†’ DB ì ì¬",
        "ê±°ë˜ì²˜ ì •ê·œí™”",
        "ê±°ë˜ì²˜ ì „ëµ ë¦¬í¬íŠ¸",
    ],
    index=0,
)

if st.sidebar.button("ğŸ”„ ì „ì²´ ìºì‹œ ë¹„ìš°ê¸°"):
    st.cache_data.clear()
    st.rerun()

try:
    if menu == "ì¬ê³  / í’ˆëª© ë§¤í•‘":
        show_inventory_page()
    elif menu == "ë§¤ì¶œ ì—‘ì…€ â†’ DB ì ì¬":
        show_sales_import_page()
    elif menu == "ê±°ë˜ì²˜ ì •ê·œí™”":
        show_customer_normalize_page()
    else:
        show_strategy_page()
except Exception as e:
    st.error("ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ì•„ë˜ ë‚´ìš©ì„ í™•ì¸í•˜ì„¸ìš”.")
    st.exception(e)
